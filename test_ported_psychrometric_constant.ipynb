{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fdf765e-36ac-4dd6-a450-4bbda8900b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import unittest\n",
    "from test.test_crop import Test_psychrometric_constant\n",
    "\n",
    "import cupy as cp\n",
    "import dask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import src.geocat.comp.crop as geo\n",
    "import xarray as xr\n",
    "csvpath = \"psychrometric_constant_ported_test_numpy.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb53418-ba38-451d-81d7-8bfa93fa5830",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48da88f-2a8a-4683-8b68-0ae7faaea2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot(allData,name):\n",
    "    arraysizes = np.unique(allData['ArraySize'])\n",
    "    sd_numpy = np.zeros(len(arraysizes))\n",
    "    sd_cupy = np.zeros(len(arraysizes))\n",
    "    y_numpy = np.zeros(len(arraysizes))\n",
    "    y_cupy = np.zeros(len(arraysizes))\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    for i in range(0,len(arraysizes)):\n",
    "        cupydata = allData.loc[(allData['ArraySize'] == arraysizes[i]) & (allData['Approach'] == 'cupy')]\n",
    "        numpydata = allData.loc[(allData['ArraySize'] == arraysizes[i]) & (allData['Approach'] == 'numpy')]\n",
    "        y_cupy[i] = np.mean(cupydata['Runtime(s)'])\n",
    "        y_numpy[i] = np.mean(numpydata['Runtime(s)'])\n",
    "        sd_cupy[i] = np.std(cupydata['Runtime(s)'])\n",
    "        sd_numpy[i] = np.std(numpydata['Runtime(s)'])\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    ax.errorbar(arraysizes, y_numpy, yerr=sd_numpy, fmt='-o',label='numpy')\n",
    "    ax.errorbar(arraysizes, y_cupy, yerr=sd_cupy, fmt='-o',label='cupy')\n",
    "    ax.legend();  # Add a legend.\n",
    "    ax.set_xlabel('ArraySize')  # Add an x-label to the axes.\n",
    "    ax.set_ylabel('Runtime(s)')  # Add a y-label to the axes.\n",
    "    ax.set_title((\"Test_psychrometric_constant\"))\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    plt.savefig(name,dpi=fig.dpi)\n",
    "\n",
    "def test_validation(res_numpy,res_cupy):\n",
    "    assert np.allclose(res_numpy,res_cupy, atol=0.0000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9687f-c6cb-4120-8c69-3b546a655240",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0ac93b-f893-4071-81cb-7d531098c60c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CPU cluster on PBS cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f33d62-c47c-4559-b598-9d0fa60c3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask.array as da\n",
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "clusterCPU = PBSCluster(memory='100 GB',\n",
    "                     processes=3,\n",
    "                     cores=3,\n",
    "                     queue='casper',\n",
    "                     walltime='02:00:00',\n",
    "                     resource_spec='select=1:ncpus=3:mem=100gb')\n",
    "print(clusterCPU.job_script())\n",
    "clusterCPU.scale(1)\n",
    "client = Client(clusterCPU)\n",
    "#cluster.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d8b0b8-eb23-44d0-8a31-c668b7cf097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61315414-5253-42a5-9ca4-56e432ac6052",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CUDA cluster on PBS cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4e500-7e52-40c9-9875-ed064d303005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask.array as da\n",
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "clusterCUDA = PBSCluster(memory='200 GB',\n",
    "                     processes=1,\n",
    "                     cores=1,\n",
    "                     queue='casper',\n",
    "                     walltime='02:00:00',\n",
    "                     resource_spec='select=1:ncpus=1:ngpus=1:mem=200gb')\n",
    "print(clusterCUDA.job_script())\n",
    "clusterCUDA.scale(1)\n",
    "client = Client(clusterCUDA)\n",
    "#cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b086ad-4d93-47ac-8f68-633c599522b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a6dce-2862-42fd-b577-fd0d3b57a430",
   "metadata": {},
   "source": [
    "## Initializing Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3103bd5-f76e-4fd8-9531-f1bbccb99aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_power = 10\n",
    "chunksize = 10**5\n",
    "pressure_arrays = []\n",
    "for i in range(1,max_power):\n",
    "    pressure_arrays.append(xr.DataArray(np.random.uniform(low=0.00066474,high=0.066474,size=10**i)))\n",
    "numpy_results = []\n",
    "cupy_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f57ff7-fb58-43f3-be12-61af00641488",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Numpy input and CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d383dec-7760-4e14-bdc5-3fd881b00809",
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = np\n",
    "for i in range(max_power-1):\n",
    "    pressure = pressure_arrays[i].data\n",
    "    ncl_gt1 = geo.psychrometric_constant(pressure, use_gpu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc79e29-3441-4d2c-8774-63a67c55bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ncl_gt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82fbf02-f23f-44f1-a917-b276b32036da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Numpy input and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d604910b-524e-4f82-94ca-216c231f01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_power-1):\n",
    "    pressure = pressure_arrays[i].data\n",
    "    ncl_gt2 = geo.psychrometric_constant(pressure, use_gpu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a9073-327b-47b2-ab13-a7583fa9c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ncl_gt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a4fd4c-2b40-47aa-a090-6ce513e4b420",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Xarray input and CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554f237-484f-4890-844c-6b6dc2c3d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.geocat.comp.comp_util import _is_duck_array, _convert_to_gpu_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7acfde6-aecb-458c-af35-3edafa466c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_power-1):\n",
    "    pressure = pressure_arrays[i]\n",
    "    ncl_gt1 = geo.psychrometric_constant(pressure, use_gpu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f9ecf0-835b-4722-a096-c6955f6e3db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ncl_gt1.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d892e2-66a7-42e6-8054-909d510ce5dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Xarray input and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a507eef-4dbf-4ef3-8099-e78b0194df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_power-1):\n",
    "    pressure = pressure_arrays[i]\n",
    "    ncl_gt1 = geo.psychrometric_constant(pressure, use_gpu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db03af7-8188-431c-ae7c-a6e0eb969ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncl_gt2.data.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524bdcc-e83c-4482-979b-1abf1277ac74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Dask input with CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a1e244-71a8-4812-a8f5-0d3c3aaebb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    pressure = pressure_arrays[i]\n",
    "    ncl_gt1 = geo.psychrometric_constant(pressure, use_gpu = False).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e673c-96d6-46a2-a6a8-abe2c899d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncl_gt1.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08135d44-53ff-4c5a-b1f5-6d437510d2fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Dask input with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0220d-520d-45c8-8db3-fc9a44ea136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(clusterCUDA)\n",
    "for i in range(2):\n",
    "    pressure = pressure_arrays[i]\n",
    "    ncl_gt2 = geo.psychrometric_constant(pressure, use_gpu = True).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69574752-1b9b-45fe-abca-e21e2d750f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncl_gt2.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acc4745-d762-4eb4-b5ef-4dcb31ad0671",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unittests with CPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed32a55-c85c-4fa7-bd45-3ff4395a0cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/hkashgar/conda-envs/geocat/lib/python3.10/site-packages/distributed/node.py:177: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 36991 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#client = Client(clusterCPU)\n",
    "test = Test_psychrometric_constant()\n",
    "\n",
    "test.setUpClass()\n",
    "test.test_float_input(use_gpu = False)\n",
    "test.test_list_input(use_gpu = False)\n",
    "test.test_numpy_input(use_gpu = False)\n",
    "test.test_multi_dimensional_input(use_gpu = False)\n",
    "test.test_xarray_input(use_gpu = False)\n",
    "test.test_dask_compute(use_gpu = False)\n",
    "test.test_dask_lazy(use_gpu = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833e46b4-5d32-4ee4-b24c-dd4d90d57b20",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unittests with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c907e70-e181-4328-8083-7ac9ab53e734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/hkashgar/conda-envs/geocat/lib/python3.10/site-packages/distributed/node.py:177: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 44846 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m test\u001b[38;5;241m.\u001b[39mtest_numpy_input(use_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m test\u001b[38;5;241m.\u001b[39mtest_multi_dimensional_input(use_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_xarray_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m test\u001b[38;5;241m.\u001b[39mtest_dask_compute(use_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m test\u001b[38;5;241m.\u001b[39mtest_dask_lazy(use_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/GPU_data_analysis_rapids/geocat-comp/test/test_crop.py:212\u001b[0m, in \u001b[0;36mTest_psychrometric_constant.test_xarray_input\u001b[0;34m(self, use_gpu)\u001b[0m\n\u001b[1;32m    209\u001b[0m pressure \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpressure_gt)\n\u001b[1;32m    210\u001b[0m expected \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mncl_gt)\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsychrometric_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpressure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mexpected\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m                   \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.005\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mallclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/glade/work/hkashgar/conda-envs/geocat/lib/python3.10/site-packages/numpy/core/numeric.py:2251\u001b[0m, in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2180\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[1;32m   2181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mallclose\u001b[39m(a, b, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-5\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-8\u001b[39m, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2182\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;124;03m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[1;32m   2184\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2249\u001b[0m \n\u001b[1;32m   2250\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2251\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(\u001b[43misclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(res)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/glade/work/hkashgar/conda-envs/geocat/lib/python3.10/site-packages/numpy/core/numeric.py:2344\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2341\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m errstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   2342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m less_equal(\u001b[38;5;28mabs\u001b[39m(x\u001b[38;5;241m-\u001b[39my), atol \u001b[38;5;241m+\u001b[39m rtol \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mabs\u001b[39m(y))\n\u001b[0;32m-> 2344\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2345\u001b[0m y \u001b[38;5;241m=\u001b[39m asanyarray(b)\n\u001b[1;32m   2347\u001b[0m \u001b[38;5;66;03m# Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).\u001b[39;00m\n\u001b[1;32m   2348\u001b[0m \u001b[38;5;66;03m# This will cause casting of x later. Also, make sure to allow subclasses\u001b[39;00m\n\u001b[1;32m   2349\u001b[0m \u001b[38;5;66;03m# (e.g., for numpy.ma).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2352\u001b[0m \u001b[38;5;66;03m#       timedelta works if `atol` is an integer or also a timedelta.\u001b[39;00m\n\u001b[1;32m   2353\u001b[0m \u001b[38;5;66;03m#       Although, the default tolerances are unlikely to be useful\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/hkashgar/conda-envs/geocat/lib/python3.10/site-packages/xarray/core/common.py:143\u001b[0m, in \u001b[0;36mAbstractArray.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, dtype: DTypeLike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/glade/work/hkashgar/conda-envs/geocat/lib/python3.10/site-packages/xarray/core/dataarray.py:642\u001b[0m, in \u001b[0;36mDataArray.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    The array's data as a numpy.ndarray.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03m    type does not support coercion like this (e.g. cupy).\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[0;32m/glade/work/hkashgar/conda-envs/geocat/lib/python3.10/site-packages/xarray/core/variable.py:512\u001b[0m, in \u001b[0;36mVariable.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;124;03m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_as_array_or_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/hkashgar/conda-envs/geocat/lib/python3.10/site-packages/xarray/core/variable.py:252\u001b[0m, in \u001b[0;36m_as_array_or_item\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_as_array_or_item\u001b[39m(data):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the given values as a numpy array, or as an individual item if\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    it's a 0d datetime64 or timedelta64 array.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m    TODO: remove this (replace with np.asarray) once these issues are fixed\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32mcupy/_core/core.pyx:1397\u001b[0m, in \u001b[0;36mcupy._core.core.ndarray.__array__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly."
     ]
    }
   ],
   "source": [
    "#client = Client(clusterCUDA)\n",
    "test = Test_psychrometric_constant()\n",
    "\n",
    "test.setUpClass()\n",
    "test.test_float_input(use_gpu = True)\n",
    "test.test_list_input(use_gpu = True)\n",
    "test.test_numpy_input(use_gpu = True)\n",
    "test.test_multi_dimensional_input(use_gpu = True)\n",
    "test.test_xarray_input(use_gpu = True)\n",
    "test.test_dask_compute(use_gpu = True)\n",
    "test.test_dask_lazy(use_gpu = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89402be5-a57e-4037-a487-e3523d2ae4ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Benchmark Results for different Array Sizes (NUMPY/CUPY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864afb6b-31c7-4f01-90ad-806fc289245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test_psychrometric_constant main body\n",
    "Routine = \"psychrometric_constant\"\n",
    "print(Routine)\n",
    "allData = pd.DataFrame()\n",
    "#For different Array sizes\n",
    "for i in range(1,max_power):\n",
    "    ArraySize = 10**i\n",
    "    pressure = pressure_arrays[i-1].data\n",
    "    print(\"Array size: \", ArraySize)\n",
    "    #for numpy and cupy both\n",
    "    for xp in [np,cp]:\n",
    "        #calculation will be repeated 10 time to get the less biased performance results\n",
    "        repsize = 10\n",
    "        repeat = np.zeros([repsize])\n",
    "        for rep in range(0,repsize):\n",
    "            #create different sizes of arrays\n",
    "            if(xp == cp):\n",
    "                res_cupy = geo.psychrometric_constant(pressure,True)\n",
    "                cp.cuda.runtime.deviceSynchronize()\n",
    "                time1 = time.time()\n",
    "                res_cupy = geo.psychrometric_constant(pressure,True)\n",
    "                cp.cuda.runtime.deviceSynchronize()\n",
    "                time2 = time.time()\n",
    "                repeat[rep] = time2-time1\n",
    "            else:\n",
    "                time1 = time.time()\n",
    "                res_numpy = geo.psychrometric_constant(pressure,False)\n",
    "                time2 = time.time()\n",
    "                repeat[rep] = time2-time1\n",
    "        #save times\n",
    "        data = {'Routine': np.repeat(Routine, repsize),\n",
    "                'Input':\"NumPy input\",\n",
    "                'Approach': np.repeat(xp.__name__ , repsize),\n",
    "                'ArraySize': np.repeat(ArraySize , repsize),\n",
    "                'iteration' : np.arange(1,repsize+1),\n",
    "                'Runtime(s)': repeat}\n",
    "\n",
    "        allData = pd.concat([allData,pd.DataFrame(data)], ignore_index=True)\n",
    "        print(xp.__name__,np.mean(repeat), \"seconds\")\n",
    "    test_validation(res_numpy,res_cupy)\n",
    "try:\n",
    "    previous = pd.read_csv(csvpath)\n",
    "    previous = pd.concat([previous,allData])\n",
    "except FileNotFoundError:\n",
    "    previous = allData\n",
    "previous.to_csv(csvpath, index=False)\n",
    "plot(allData,\"Test_psychrometric_constant_ported_numpy.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bcd16c-5c6c-4cad-9e38-73b9f26cbcd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results for different ArraySizes Xarray (with NumPy/CuPy arrays inside the Xarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2a39d2-8527-4145-8ac9-f03b466c29ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test psychrometric_constant on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8658fe1-d6ff-4187-90e4-4980769f41e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(clusterCPU)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6e2c6-2b68-488e-adef-6e0e9450d744",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvpath = \"psychrometric_constant_ported_test_xarray.csv\"\n",
    "#Test_psychrometric_constant main body\n",
    "Routine = \"psychrometric_constant\"\n",
    "print(Routine)\n",
    "allData = pd.DataFrame()\n",
    "#For different Array sizes\n",
    "for i in range(1,max_power):\n",
    "    ArraySize = 10**i\n",
    "    print(\"Array size: \", ArraySize)\n",
    "    pressure = pressure_arrays[i-1].data\n",
    "    #for numpy and cupy both\n",
    "    xp = np \n",
    "    repsize = 10\n",
    "    repeat = np.zeros([repsize])\n",
    "    for rep in range(0,repsize):\n",
    "    #create different sizes of arrays\n",
    "        numpy_res = geo.psychrometric_constant(pressure , False)\n",
    "        time1 = time.time()\n",
    "        numpy_res = geo.psychrometric_constant(pressure , False)\n",
    "        time2 = time.time()\n",
    "        repeat[rep] = time2-time1\n",
    "    numpy_results.append(numpy_res)\n",
    "    #save times\n",
    "    data = {'Routine': np.repeat(Routine, repsize),\n",
    "            'Input':\"Xarray with NumPy input\",\n",
    "            'Approach': np.repeat(xp.__name__ , repsize),\n",
    "            'ArraySize': np.repeat(ArraySize , repsize),\n",
    "            'iteration' : np.arange(1,repsize+1),\n",
    "            'Runtime(s)': repeat}\n",
    "    allData = pd.concat([allData,pd.DataFrame(data)], ignore_index=True)\n",
    "    print(xp.__name__,np.mean(repeat), \"seconds\")\n",
    "try:\n",
    "    previous = pd.read_csv(csvpath)\n",
    "    previous = pd.concat([previous,allData])\n",
    "except FileNotFoundError:\n",
    "    previous = allData\n",
    "previous.to_csv(csvpath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879a9679-29e3-4c11-8ae1-420f9e049814",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test psychrometric_constant on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c39449d-eb3e-4b33-9092-9394c54ce360",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(clusterCUDA)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f5657d-5b18-47fd-afd8-4f8c1d7981a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test_psychrometric_constant main body\n",
    "Routine = \"psychrometric_constant\"\n",
    "print(Routine)\n",
    "#For different Array sizes\n",
    "for i in range(1,max_power):\n",
    "    ArraySize = 10**i\n",
    "    pressure = pressure_arrays[i-1]\n",
    "    print(\"Array size: \", ArraySize)\n",
    "    #for numpy and cupy both\n",
    "    xp = cp\n",
    "        #calculation will be repeated 10 time to get the less biased performance results\n",
    "    repsize = 10\n",
    "    repeat = np.zeros([repsize])\n",
    "    for rep in range(0,repsize):\n",
    "        #create different sizes of arrays\n",
    "        cupy_res = geo.psychrometric_constant(pressure, True)\n",
    "        cp.cuda.runtime.deviceSynchronize()\n",
    "        time1 = time.time()\n",
    "        cupy_res = geo.psychrometric_constant(pressure, True)\n",
    "        cp.cuda.runtime.deviceSynchronize()\n",
    "        time2 = time.time()\n",
    "        repeat[rep] = time2-time1\n",
    "    cupy_results.append(cupy_res)\n",
    "    #save times\n",
    "    data = {'Routine': np.repeat(Routine, repsize),\n",
    "            'Input':\"Xarray with NumPy input\",\n",
    "            'Approach': np.repeat(xp.__name__ , repsize),\n",
    "            'ArraySize': np.repeat(ArraySize , repsize),\n",
    "            'iteration' : np.arange(1,repsize+1),\n",
    "            'Runtime(s)': repeat}\n",
    "    allData = pd.concat([allData,pd.DataFrame(data)], ignore_index=True)\n",
    "    print(xp.__name__,np.mean(repeat), \"seconds\")\n",
    "\n",
    "try:\n",
    "    previous = pd.read_csv(csvpath)\n",
    "    previous = pd.concat([previous,allData])\n",
    "except FileNotFoundError:\n",
    "    previous = allData\n",
    "previous.to_csv(csvpath, index=False)\n",
    "plot(allData,\"Test_psychrometric_constant_ported_xarray.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a17406-2783-4389-b78e-8142cf27e5ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8a3094-2533-40d0-b6d4-2a2783c88aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation \n",
    "for i in range(len(numpy_results)):\n",
    "    test_validation(cupy_results[i].data,numpy_results[i].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58db857-2ab8-4466-8340-67f03b646a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cupy_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac048e-c86e-429b-880a-2526c5492581",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72bc7fa-4fa1-4616-abff-5fe2ebe22114",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Benchmark Results for different ArraySizes Xarray (with Dask arrays inside the Xarray, then dask array type is either NumPy or CuPy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8fc679-e63d-4c66-bf0c-001720e0022f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test psychrometric_constant on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e22a53-9c20-4995-9bc2-d319c17456a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(clusterCPU)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71296bd-7005-4099-9704-2aff49831259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csvpath = \"psychrometric_constant_ported_test_dask.csv\"\n",
    "#Test_psychrometric_constant main body\n",
    "Routine = \"psychrometric_constant\"\n",
    "print(Routine)\n",
    "allData = pd.DataFrame()\n",
    "#For different Array sizes\n",
    "for i in range(1,max_power):\n",
    "    ArraySize = 10**i\n",
    "    print(\"Array size: \", ArraySize)\n",
    "    rh_def = rh_def_arrays[i-1].chunk(chunksize)\n",
    "    tk_def = tk_def_arrays[i-1].chunk(chunksize)\n",
    "    #for numpy and cupy both\n",
    "    xp = np\n",
    "    #calculation will be repeated 10 time to get the less biased performance results\n",
    "    repsize = 10\n",
    "    repeat = np.zeros([repsize])\n",
    "    for rep in range(0,repsize):\n",
    "        #create different sizes of arrays\n",
    "        numpy_res = geo.psychrometric_constant(tk_def, rh_def, False).compute()\n",
    "        time1 = time.time()\n",
    "        numpy_res = geo.psychrometric_constant(tk_def, rh_def, False).compute()\n",
    "        time2 = time.time()\n",
    "        repeat[rep] = time2-time1\n",
    "        #save times\n",
    "    numpy_results.append(numpy_res)\n",
    "    data = {'Routine': np.repeat(Routine, repsize),\n",
    "            'Input':\"Xarray with Dask array input\",\n",
    "            'Approach': np.repeat(xp.__name__ , repsize),\n",
    "            'ArraySize': np.repeat(ArraySize , repsize),\n",
    "            'iteration' : np.arange(1,repsize+1),\n",
    "            'Runtime(s)': repeat}\n",
    "    allData = pd.concat([allData,pd.DataFrame(data)], ignore_index=True)\n",
    "    print(xp.__name__,np.mean(repeat), \"seconds\")\n",
    "\n",
    "try:\n",
    "    previous = pd.read_csv(csvpath)\n",
    "    previous = pd.concat([previous,allData])\n",
    "except FileNotFoundError:\n",
    "    previous = allData\n",
    "previous.to_csv(csvpath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2364591d-d6df-44e0-82e3-6aaac0481a7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test psychrometric_constant on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c47630-a644-43cf-918c-a59caef436ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(clusterCUDA)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e801b0-367c-4000-88be-29db5abaecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test_psychrometric_constant main body\n",
    "Routine = \"psychrometric_constant\"\n",
    "print(Routine)\n",
    "#For different Array sizes\n",
    "for i in range(1,max_power):\n",
    "    ArraySize = 10**i\n",
    "    print(\"Array size: \", ArraySize)\n",
    "    rh_def = rh_def_arrays[i-1].chunk(chunksize)\n",
    "    tk_def = tk_def_arrays[i-1].chunk(chunksize)\n",
    "    #for numpy and cupy both\n",
    "    xp = cp\n",
    "    #calculation will be repeated 10 time to get the less biased performance results\n",
    "    repsize = 10\n",
    "    repeat = np.zeros([repsize])\n",
    "    for rep in range(0,repsize):\n",
    "        #create different sizes of arrays\n",
    "        cupy_res = geo.psychrometric_constant(tk_def, rh_def, True).compute()\n",
    "        cp.cuda.runtime.deviceSynchronize()\n",
    "        time1 = time.time()\n",
    "        cupy_res = geo.psychrometric_constant(tk_def, rh_def, True).compute()\n",
    "        cp.cuda.runtime.deviceSynchronize()\n",
    "        time2 = time.time()\n",
    "        repeat[rep] = time2-time1\n",
    "        #save times\n",
    "    cupy_results.append(cupy_res)\n",
    "    data = {'Routine': np.repeat(Routine, repsize),\n",
    "            'Input':\"Xarray with Dask array input\",\n",
    "            'Approach': np.repeat(xp.__name__ , repsize),\n",
    "            'ArraySize': np.repeat(ArraySize , repsize),\n",
    "            'iteration' : np.arange(1,repsize+1),\n",
    "            'Runtime(s)': repeat}\n",
    "    new = pd.DataFrame(data)\n",
    "    allData = pd.concat([allData,new], ignore_index=True)\n",
    "    print(xp.__name__,np.mean(repeat), \"seconds\")\n",
    "    #print(np.allclose(cupy_res.data,numpy_res.data,atol=0.0000001))\n",
    "try:\n",
    "    previous = pd.read_csv(csvpath)\n",
    "    previous = pd.concat([previous,allData])\n",
    "except FileNotFoundError:\n",
    "    previous = allData\n",
    "previous.to_csv(csvpath, index=False)\n",
    "\n",
    "plot(allData,\"Test_psychrometric_constant_ported_dask.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bbacbe-6b26-4fd1-ba7c-75f423aff5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cupy_res.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce7400-1da6-4a10-a3b3-996d19d3877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_res.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e202cd-1651-4c15-8c86-35e6c5dc83d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9bf6f-dea4-42d8-b125-7a94eb7942b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation \n",
    "for i in range(len(numpy_results)):\n",
    "    test_validation(cupy_results[i].data,numpy_results[i].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b0f94-92cd-4e13-ae04-cbb5c75dac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42399d9-338b-4f91-a755-620504f97e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cupy_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b2754-2bc1-44c3-8248-f3d434593155",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(numpy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31393ae-590f-4179-9d6b-b41158730396",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Only comparing \"compute()\" runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f0d05-5a4e-459e-a9a5-c830d7d206f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10**5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e0b661-f8e4-4d5f-924b-f3b84f064d6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7bfe2-8759-4d15-8a2b-c1016410ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(clusterCPU)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b546e4-0d12-424f-acd6-17c454ab1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvpath = \"psychrometric_constant_ported_test_dask_compute_10.csv\"\n",
    "#Test_psychrometric_constant main body\n",
    "Routine = \"psychrometric_constant\"\n",
    "print(Routine)\n",
    "allData = pd.DataFrame()\n",
    "#For different Array sizes\n",
    "for i in range(1,7):\n",
    "    ArraySize = 10**i\n",
    "    print(\"Array size: \", ArraySize)\n",
    "    rh_def = rh_def_arrays[i-1].chunk(chunksize)\n",
    "    tk_def = tk_def_arrays[i-1].chunk(chunksize)\n",
    "    #for numpy and cupy both\n",
    "    xp = np\n",
    "    #calculation will be repeated 10 time to get the less biased performance results\n",
    "    repsize = 10\n",
    "    repeat = np.zeros([repsize])\n",
    "    for rep in range(0,repsize):\n",
    "        #create different sizes of arrays\n",
    "        numpy_res = geo.psychrometric_constant(tk_def, rh_def,False)\n",
    "        numpy_res.compute()\n",
    "        time1 = time.time()\n",
    "        numpy_res = numpy_res.compute()\n",
    "        time2 = time.time()\n",
    "        repeat[rep] = time2-time1\n",
    "        #save times\n",
    "    numpy_results.append(numpy_res)\n",
    "    data = {'Routine': np.repeat(Routine, repsize),\n",
    "            'Input':\"Xarray with Dask array input compute\",\n",
    "            'Approach': np.repeat(xp.__name__ , repsize),\n",
    "            'ArraySize': np.repeat(ArraySize , repsize),\n",
    "            'iteration' : np.arange(1,repsize+1),\n",
    "            'Runtime(s)': repeat}\n",
    "    allData = pd.concat([allData,pd.DataFrame(data)], ignore_index=True)\n",
    "    print(xp.__name__,np.mean(repeat), \"seconds\")\n",
    "\n",
    "try:\n",
    "    previous = pd.read_csv(csvpath)\n",
    "    previous = pd.concat([previous,allData])\n",
    "except FileNotFoundError:\n",
    "    previous = allData\n",
    "previous.to_csv(csvpath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a8849-0840-4664-93f1-e6385b05a282",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0724428-a3c2-45b3-a2b9-89faaa8e538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(clusterCUDA)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c885d0-a02d-48e5-b545-ae7b7f052349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test_psychrometric_constant main body\n",
    "Routine = \"psychrometric_constant\"\n",
    "print(Routine)\n",
    "#For different Array sizes\n",
    "for i in range(1,7):\n",
    "    ArraySize = 10**i\n",
    "    print(\"Array size: \", ArraySize)\n",
    "    rh_def = rh_def_arrays[i-1].chunk(chunksize)\n",
    "    tk_def = tk_def_arrays[i-1].chunk(chunksize)\n",
    "    #for numpy and cupy both\n",
    "    xp = cp\n",
    "    #calculation will be repeated 10 time to get the less biased performance results\n",
    "    repsize = 10\n",
    "    repeat = np.zeros([repsize])\n",
    "    for rep in range(0,repsize):\n",
    "        #create different sizes of arrays\n",
    "        cupy_res = geo.psychrometric_constant(tk_def, rh_def,True)\n",
    "        cupy_res.compute()\n",
    "        cp.cuda.runtime.deviceSynchronize()\n",
    "        time1 = time.time()\n",
    "        cupy_res = cupy_res.compute()\n",
    "        cp.cuda.runtime.deviceSynchronize()\n",
    "        time2 = time.time()\n",
    "        repeat[rep] = time2-time1\n",
    "        #save times\n",
    "    cupy_results.append(cupy_res)\n",
    "    data = {'Routine': np.repeat(Routine, repsize),\n",
    "            'Input':\"Xarray with Dask array input compute\",\n",
    "            'Approach': np.repeat(xp.__name__ , repsize),\n",
    "            'ArraySize': np.repeat(ArraySize , repsize),\n",
    "            'iteration' : np.arange(1,repsize+1),\n",
    "            'Runtime(s)': repeat}\n",
    "    new = pd.DataFrame(data)\n",
    "    allData = pd.concat([allData,new], ignore_index=True)\n",
    "    print(xp.__name__,np.mean(repeat), \"seconds\")\n",
    "    #print(np.allclose(cupy_res.data,numpy_res.data,atol=0.0000001))\n",
    "try:\n",
    "    previous = pd.read_csv(csvpath)\n",
    "    previous = pd.concat([previous,allData])\n",
    "except FileNotFoundError:\n",
    "    previous = allData\n",
    "previous.to_csv(csvpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1fdf44-4cba-4a10-8795-8e9297b0b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(allData,\"Test_psychrometric_constant_ported_compute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970184b-f441-4b3e-8d4a-acd8d0f9a09e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fa41a-d9a8-4671-a851-4371003707c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation \n",
    "for i in range(len(numpy_results)):\n",
    "    test_validation(cupy_results[i].data,numpy_results[i].data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geocat]",
   "language": "python",
   "name": "conda-env-geocat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
